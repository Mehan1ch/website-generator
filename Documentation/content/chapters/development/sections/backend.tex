\section{Backend}
\subsection{Setup}
I implemented the backend primarily using the Laravel PHP web framework as stated beforehand.
As the first step the application has to be installed and set up.
This can be done with Laravel's own installer, where many application templates can be selected.
A React template is available, however that uses Inertia.JS by default which is a package that enables the frontend to be server side routed.
I wished to opt out of this and develop a traditional API based SPA, so I decided to use the minimal setup.
So Laravel will serve as an API backend and the view layer of the MVC architecture will be entirely handled by the frontend.

After installation, I decided to install the Laravel Sail package which provides a preconfigured development Docker Compose setup, and also provides options to install additional components into our environment.
The extra containers in our case will be the MySQL database, the Mailpit SMTP test server and the MinIO S3 compatible object storage.
However, the Laravel creators published Sail as a package which by default would need a local PHP and Composer (PHP's package manager) installation.
This would kind of defeat its purpose.
Luckily this can be avoided by using a temporary PHP container to quickly install initial dependencies and then use the Sail application for further required packages.

Afterwards the provided \texttt{.env.example} file needs to be copied to \texttt{.env} and the appropriate environment variables need to be set, including the mail server, database and object storage connections.
In the MinIO object storage a bucket to store files must be created and set to public so that the links generated to the files can be accessed by the other applications.
Finally, the application key must be initialized using the Artisan CLI and the default database migrations have to be run.

\subsection{Eloquent ORM}

Let me start building up the backend's feature set from the bottom, starting with the parts of the Eloquent ORM.
The database schema of the backend including the most important tables can be seen on Figure \ref{fig:database}.

Laravel has some other default tables, related to built-in features such as jobs and caching that I omitted from the diagram for better clarity as they will be unused in the application.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{./figures/database.png}
  \caption{Database schema}
  \label{fig:database}
\end{figure}

All the tables have a corresponding migration file that defines a migration class with an up and down method.
In these methods using the provided schema class we can define the blueprints of the tables with their fields and data types, and how to create and drop them.
The Eloquent ORM then when running the migrations will take care of translating it to the query language of the chosen database management system.

The users table is auto generated, the only change I made is regarding the ID (Identifier) field.
In all tables and models I opted to switch from the default integer ID to UUIDv7 (Universally Unique Identifiers version 7) which are time-based sortable universally unique identifiers composed of 32 hexadecimal digits.
The application uses the simplest form of tenancy where each user is a tenant as that is sufficient for the current requirements.

All tables by default also have two timestamp fields a \texttt{created\_at} and an \texttt{updated\_at}. Laravel automatically manages these and casts them by default to the included carbon class, which provides helper methods to manage times professionally.

The Spatie Laravel Permission package adds the role related tables, which I will talk about in more detail in the authorization Subsection \ref{subsection:authorization}.

On the other hand the Spatie Media Library provides the media table which will be used to store profile pictures and the HTML files of the static pages.
The application uses the password reset tokens and sessions table for authentication related features.
The Sites table store the websites of the users. Each site must have a unique subdomain that will be assigned to it upon creation and which cannot be changed later.

Also, worth mentioning that each site also has a state that can be either draft or published, to track changes and whether they are visible to the end users.
This is implemented using the Spatie Model States library which adds an easy to configure state machine pattern support with helper functions such as checking viable transitions.
It uses an abstract state (\texttt{PublishingState}) class with actual states being the concrete implementations (\texttt{Published}, \texttt{Draft}).
Allowed transitions and transition handlers are also easy to configure and customize.

A site can also have pages which need a corresponding URL segment (e.g., \texttt{/about}) for routing.
The database stores the pages content in a zlib compressed and base64 encoded format for better transfer and storage efficiency, but can be cast to the uncompressed version if needed.
The structure of the content will be further specified in Section \ref{section:frontend}, but in short it is a JSON file encoding a tree structure.
Pages also take advantage of the media library and S3 object storage to store the page's HTML in files.
Last but not least the schemas table is a mix of the previous two, having both a content identical to that of the pages table and the same published and draft state as sites.
Schemas allow administrators to create and publish page schemas that users can base their own pages off of.

The models paired with the tables contain most of the business logic that is independent of routes (heavy models).
This includes defining all relationships and their inverses, like in the case of sites and pages a hasMany, and it's inverse belongsTo functions, defining fillable fields that can be assigned from requests, and any custom casts and attributes.
The former include casting to the aforementioned state classes while the latter includes accessing the decompressed and decoded content and the storage and retrieval of the HTML content of pages.
Models register media collections for storing files by setting its name, accepted MIME (Multipurpose Internet Mail Extensions) types and the amount of files they can hold.

Finally, for most of the mentioned models I extended the special boot method with additional functionality. Inside this the CRUD functionality can be extended with additional logic.
Examples include ensuring that sites transfer to the draft state when one of their pages gets updated, ensuring that a home page (\texttt{/}) exists for all sites, and relationship and media clean up logic upon model deletion.

A feature related to models is factories which allows the developer to create instances of models with set default attributes and persist them to the database.
Another related feature is database seeding which allows us to populate the database with initial data.
Since I use the aforementioned capabilities mostly for testing I will go into more detail about them in Section \ref{section:backend-testing}.
For development purposes, however I use the user model's factory to create a super-admin user and seed roles and permissions into the database.
I will talk about the previously mentioned features more in Subsection \ref{subsection:authorization}.

The final component related to the Eloquent ORM I used and want to mention here is API resource classes. They provide a way to transform models into the JSON format that is returned to the application's frontend.
It can be thought of as a Data Transfer Object (DTO) implementation as resource classes allow fine granular control over the returned properties.
Fields can be hidden from models, relationships can be included with select fields, and any custom or calculated field can be defined.
Moreover, resource collection classes can be defined which define how to return a collection of the given model as opposed to returning a singular instance.
Furthermore, resources classes can also be defined without them being connected to a given model.

For each model and endpoint I defined a corresponding resource and resource collection class.
In order to parse request and responses from the proxy application I implemented custom deployment resources as well.
I organized all of these classes  according to the API versioning, to which refer to Subsection \ref{subsection:crud}.

\subsection{Authentication}
Moving on from the ORM features, next I will describe the implementation of the authentication capabilities of the backend.
The combination of two packages maintained by the Laravel team provide the functionality, the first being Laravel Sanctum, while the second is Laravel Fortify.

Laravel Sanctum provides API token based, SPA session based and Mobile token based authentication methods and provides CORS (Cross-Origin Resource Sharing) and CSRF (Cross-Site Request Forgery) protections for better security.
Out of these three I only used the SPA session based authentication using cookies for the frontend.
To begin with the \texttt{SANCTUM\_STATEFUL\_DOMAINS} environment variable has to be set with the frontend and proxy URLs.
Next, in the application bootstrapper the stateful API global middleware has to be applied.
Lastly the CORS configuration should be published, and the allowed paths have to be set.

In contrast, Laravel Fortify provides a frontend agnostic implementation of authentication features for the backend.
In other words it implements the routes and controllers for login, registration, password reset and confirmation, email verification and two-factor authentication if needed.
Each of these features can be enabled or disabled in its own configuration file.
Additionally fortify can provide Blade templating based views for each of these features if needed however since I will use an SPA frontend I disabled them.
I also opted-out from the two-factor authentication capabilities, the rest however are fully supported by the developed application suite.

One small caveat with using a separate React frontend is that the default password reset and email verification links that are generated by the backend navigate to itself instead of the frontend.
I fixed this by overriding the link generator methods in the application service provider.
To finalize the authentication implementation the user model has to be extended from the \texttt{Authenticable} class, and has to implement the \texttt{MustVerifyEmail} interface.

\subsection{Authorization}
\label{subsection:authorization}
Strongly related to authentication is authorization.
Laravel provides gates and policies built-in for this purpose.
Gates are closures that define if the application authorizes the given user to make a certain action.

However, I won't go into more detail about them as instead I will be using Spatie's Laravel Permission package.
It allows developers to manage permissions and roles in a database.
Since it provides native enum support I implemented a role and permission enum class.

The defined roles in the system are user, which grant basic permissions after registration, admin who can manage users, schemas and access the admin panel, and lastly the super admin.
The last is the only role where I use Laravel's gates natively to grant super admins implicitly all permissions in the application service provider before any other checks.

I defined permissions separately for each model's and each CRUD method, as well as a unique permission for allowing access to the admin panel.

Since the package is storing authorization logic in the database it needs to be available after application setup.
The straightforward method to do this is to write a seeder class that initializes the default values and what maps the appropriate permissions to the corresponding roles.

Now I only needed to set up the policy classes that use these roles.
For each model an appropriate policy class can be created that checks whether the given user can be allowed to make the specified action.
Inside these functions we can check users against ownership of the roles defined before.
A special use case of policies I used is inside the page's policy where I check against the page's URL and prevent overriding or deleting the homepage.

\subsection{Core Logic}
\label{subsection:crud}
The first part of the core CRUD logic is defining the API routes in the routes folder.
Here routes can be defined for web, API, console use cases.
The web handles standard web request if Laravel were to serve the frontend as well.
Hence the React SPA takes care of this functionality the only route handler I defined here is a redirect to the frontend's index page.
The console routes can be employed to define custom artisan commands, so it remained unused in this case.

I decided to use API versioning for a cleaner design and architecture, so I prefixed all of my routes with \texttt{v1}.
If in the future a new API version would need to be released with breaking changes this allows for a cleaner transition while keeping backwards compatibility.

I grouped all routes by their respective controller that handles the incoming request.
There is a controller for each model, an avatar controller for handling profile pictures, a dashboard controller for returning the frontend dashboard's content and a deployment controller for handling making deployment requests to the proxy application.
This is worth talking about more in depth which will be done in Subsection \ref{subsection:deployment-logic}.
For each group the authentication I applied the middleware provided by Laravel Sanctum.
Apart from the user and dashboard controller the others also have the verified middleware applied onto them that ensures the user making the request must have verified their email.

The routes also have the appropriate policy methods called on them that I talked about in Subsection \ref{subsection:authorization}, to check against the given user's roles and capabilities.
Route parameters specified with e.g., \texttt{\{param\}} also get automatically dependency injected into the controller method.

Next in line I implemented Laravel's form request classes for the POST and PUT routes. They encapsulate the custom validation logic for each incoming request, which can be defined either using one of the many built-in validation rules or by creating a custom rule via a callback.
A custom rule I implemented is checking that each path segment mapped to a page must be unique within the parent site.
I used the predefined rules to validate against types, null checks, optional body parameters, sizes and file MIME types among many.
Custom auth can be implemented here, however since it is already taken care by the route policy and middleware I only provided a simple check to make sure the user exists.
I also defined a body parameters function in each form request to help the OpenAPI schema generation.

Due to the separation of concerns into the many capabilities most controllers are incredibly thin.
Frequently they are only comprised of retrieving the validated form data, performing the CRUD operation, and returning the appropriate API resource instance.
I used however the Scribe third-party package for generating an OpenAPI schema and hosted API documentation.
The package auto discovers routes and controller methods and tries to deduce the parameters, bodies, and responses, but it can have errors or shortcomings.
One way it can be helped is by giving the controller methods annotations or doc comments.
I chose the latter and provided additional descriptions for the schema generation.
It is also possible to document the routes and controllers provided by other packages, which in my case was Laravel Fortify.
This can be achieved by writing a custom YAML file describing those endpoints.

I also modified the configuration of the package so that the application publishes the generated schema on the \texttt{/docs} endpoint, which can be seen on Figure \ref{fig:openapi-backend}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{./figures/backend-docs.png}
  \caption{OpenAPI docs powered by Scribe}
  \label{fig:openapi-backend}
\end{figure}

\subsection{Deployment Logic}
\label{subsection:deployment-logic}

The deployment logic technically first begins at the page controller. When a page gets updated the frontend sends both the content and generated static HTML's body in an encoded manner for more efficient network transfer.
The HTML body then gets base64 decoded and zlib decompressed on the backend to recover the raw HTML.
Following this the HTML gets sanitized to remove any unknown tags and malicious scripts and ensure no security concerns got added by any third-party.
I implemented this by writing an HTML sanitizer service.
This service uses Symfony's \texttt{HTMLSanitizer} class that I preconfigured with the allowed and rejected elements and attributes.
Then I registered this service as a singleton in the application provider, so that Laravel can automatically discover it and inject it into the Page controller constructor.
As a part of the sanitization process if it is successful, the service afterwards injects the body into a Blade template.
This template provides the root HTML and head tags and a link to the stylesheet, which will be later injected by the proxy application.
In the end the complete HTML content gets returned and saved to the S3 storage and of course and API resource object gets sent to the frontend.

The MinIO S3 object storage showing the stored HTML files can be seen on Figure \ref{fig:minio}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{./figures/minio}
  \caption{MinIO object storage}
  \label{fig:minio}
\end{figure}

A sequence diagram displays this process to the fullest on Figure \ref{fig:html-service}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{./figures/html-service.png}
  \caption{Sequence of saving the page content}
  \label{fig:html-service}
\end{figure}

Next comes the Deployment controller which handles the actual site publishing related methods, which includes a full CRUD and the option to restart the site if need be.
I have written and registered another singleton service handling deployments that the controller forwards the incoming request to.
The deployment service then checks if the site can be transferred to the published state, builds the path and body of the request which afterwards gets deferred to the proxy application.
When the proxy returns with a response, the service forwards it to the controller which finally forwards it to the frontend.

Another sequence diagram on Figure \ref{fig:deployment-service} shows this process.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{./figures/deployment-service.png}
  \caption{Sequence diagram of the deployment process}
  \label{fig:deployment-service}
\end{figure}

\subsection{Admin Panel}

The final feature of the backend I want to talk about in this chapter is the admin panel.
It is provided by the Filament PHP package which specializes in building primarily admin panels for Laravel powered applications, but can also be used as a standalone server-driven UI framework if required.
For the first step the user model has to implement the \texttt{FilamentUser} interface.
This interface requires the implementation of the \texttt{canAccessPanel} method which has to return a boolean based on whether the user has access to the panel.
Here is where I use the previously mentioned panel access permission.
Afterwards using the included artisan command by filament the admin panel needs to be initialized.
If done then it can be visited on the \texttt{/admin} route.

The admin site is empty at first and has to be populated.
Filament defines resources which encompass the forms, pages, and schemas related to each Laravel model class.
Here UI elements Filament provides can be used to build interactive data tables, forms and views. The package provides filtering and sorting options by default, easily configurable searching and relationships can be displayed through more descriptive fields as well. For example instead of displaying the user's ID its name can be retrieved for a better UX.
Further customization is possible, but the defaults cover most use cases.

On Figure \ref{fig:admin-panel} a data table view of sites can be seen.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{./figures/admin-panel}
  \caption{List view of sites on the admin panel}
  \label{fig:admin-panel}
\end{figure}

I extended the functionality of the admin panel with the Filament StateFusion plugin created by Assem Alwaseai and the Spatie Media Library
plugin maintained by the Filament team themselves.
The former plugin integrates the Spatie Model States package into the admin panel and provides quick actions to transfer models from one state to another.
It also checks for allowed states too.
The latter plugin provides a droppable file upload field for storing files in the media library's collections and also handles displaying them.
This is mainly used to handle the user avatars from the panel.

Furthermore, I implemented a Filament relation manager for sites and pages so that the pages of the sites could be controlled from the site view.
Lastly I created a custom action group to handle deployment related operations from the admin panel.
These directly call the deployment service from the admin panel.

An overview of the previous two functionalities of a site's detail view can be seen on Figure \ref{fig:admin-detail}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{./figures/admin-detail.png}
  \caption{Site detail view on the admin panel}
  \label{fig:admin-detail}
\end{figure}